# ExamPilot V2 — 7-Day User Simulation & Evaluation

By Priya Sharma, 24, second-attempt aspirant, working part-time, targeting CSE 2027

---

## Day 1: Onboarding & First Impression

I download ExamPilot. Dark screen. A chat bubble says "Hey! I'm ExamPilot, your UPSC preparation companion."

The chat-style onboarding feels friendly — not like a form. I enter my name, pick CSE 2027, select "Second attempt" and get a motivational line: "Second attempt aspirants have the highest selection rate." Nice touch. Didn't feel condescending.

I pick "Working professional," select challenges (time management, revision, answer writing), and land on a value proposition screen with animated bullet points: "FSRS-powered spaced repetition for 90%+ retention" — I don't know what FSRS is. I just nod and move on.

Strategy selection: It recommends "Balanced." I see all 4 options. The descriptions are helpful — "Steady & sustainable" vs "High intensity." I stick with Balanced. Set exam date to June 2027.

Targets screen: 6 sliders. Daily hours (5h), new topics/day (2), revisions/week (4), tests/month (1), answer writing/week (3), CA hours/week (5). Pre-filled defaults feel reasonable. I bump daily hours to 6.

Promise screen: Pre-filled commitment text. Cute idea. I edit it slightly and hit "I Promise."

Complete: Animated checkmark, summary card. "Start Preparing." I'm in.

First dashboard: A wall of cards hits me.

- XP Progress Card (Level 1, 0 XP)
- Benchmark Score (no data yet)
- Current Affairs (empty)
- Stress Thermometer (score 50, "Moderate")
- Weakness Radar (empty)
- Velocity Card (1.0x, "On Track")
- Buffer Bank (showing some number of days)
- Today's Plan Preview (2 topics)
- Confidence Distribution (all zeros)

My honest reaction: Information overload. I count 9+ cards on the dashboard. I don't know what "Buffer Bank" means. "Velocity 1.0x" — velocity of what? The Stress Thermometer shows 50 with signals labeled "Vel", "Buf", "Tim", "Con" — I have no idea what those abbreviations mean.

I tap into the Planner tab. It says "Thursday, 27 Feb 2026 — Today's Mission", shows "Full" energy, 2 topics. One says "NEW" with "6h", another "NEW" with "4h." Topic names are real — "Oil Spills & Environmental Disasters" and "Union Budget - Structure & Components." Good. PYQ dots show importance. I can tap "Complete" or "Defer."

End of Day 1 feeling: Onboarding was smooth (8/10). Dashboard is overwhelming (4/10). Planner is clear (7/10). I don't understand half the metrics but I can follow the daily plan.

---

## Day 2–3: Following the Plan

Day 2: I complete both topics. I tap the checkmark on each. The plan shows "2/2 completed" with a celebration message: "All done for today! Great work. Rest well." Satisfying.

I check the Progress tab. Two rings: "Topics" (unweighted) and "Gravity" (weighted). I don't know the difference between these. Below: Velocity 1.0x, Buffer 4.2d, Streak 2d. The subject progress grid shows tiny rings with percentages. Most are 0%. A couple show 2-3%.

I look at Syllabus tab. Subjects are expandable. I can see every topic with its status: "Untouched", "First Pass." There's a health score on each topic and PYQ dots. This is dense but useful — I can see exactly where I stand.

Day 3: Plan gives me 2 new topics plus 1 revision of Day 1's topic. The revision is marked "REVISION" in purple. I like that it automatically scheduled a revision — I didn't have to remember. I complete all 3.

Velocity moves to 1.1x. Buffer goes up slightly. Streak says 3d. Confidence for Day 1 topics shows "fresh" in green.

Observation: The planner is doing the heavy lifting. I don't have to think about what to study. It tells me. The revision scheduling is invisible — it just appears. That's powerful.

But: I still don't understand Buffer. Is 4.2 days good or bad? There's no explanation on the card. Just a number, a progress bar, and "+0.5" in green.

---

## Day 4: I Skip a Day

Life happens. I don't study. I don't open the app.

Day 5: I open the app nervously. The planner shows new topics. Velocity dropped to 0.9x (still "On Track" but lower). Buffer dropped — now showing 3.1d. The stress thermometer nudged up slightly.

What I expected: Some acknowledgment. "You missed yesterday. Here's how to get back on track."

What I got: Nothing explicit. The numbers changed silently. I had to infer from velocity dropping and buffer shrinking that the system noticed. No banner, no message, no encouragement. The plan just continued as if nothing happened.

My feeling: Slightly abandoned. The system tracked the miss mathematically but didn't communicate it. A manual study partner would have said "No worries, let's adjust." ExamPilot just adjusted the numbers without telling me.

---

## Day 5–6: Mock Test & Poor Performance

Day 5: I record a mock test in the Progress tab. 100 questions, I attempted 80, got 45 correct across subjects. I perform badly in Indian Economy (3/15 correct) and Geography (4/12 correct).

After submission, mock analytics appear:
- Average score: 42%
- Subject accuracy grid shows Indian Economy at 20%, Geography at 33%
- Weakest topics listed
- Recommendation: "Focus on building fundamentals. Review weak subjects before attempting more mocks."

Day 6: I open the planner. This is the critical test.

The plan now includes an Indian Economy topic and a Geography topic that weren't there before. They're marked as "NEW" — the priority shifted. My Weakness Radar card on the dashboard shows Indian Economy topics in "critical" (red) and "weak" (orange) zones with recommendations like "Urgent: This topic needs immediate attention."

But here's my problem: I can't clearly see the cause and effect. The planner changed priorities, but it doesn't say "Because you scored 20% in Indian Economy in yesterday's mock, we've added these topics." I have to connect the dots myself between the mock analytics page, the weakness radar, and the planner.

The Benchmark Readiness score dropped from ~55 to ~48. Status changed to "At Risk." The component breakdown shows "Weakness: 35%" pulling the score down. This is useful but buried in the Progress tab — I wouldn't check it daily.

---

## Day 7: Weekly Review

I get a Weekly Review card in the Progress tab. It shows:

Highlights (3 bullet points):
- "Completed 8 topics this week"
- "Velocity dipped to 0.9x — consider lighter revision load"
- "1 zero-study day — try to maintain consistency"

Study metrics: 5.2h avg/day, 8 topics, 1.2x velocity
Plan adherence: 83%
Buffer change: -1.1d (red)
Streak: 5d (with the gap)

Wins:
- "Completed 8 topics this week"
- "Buffer bank grew..." — wait, it actually shrank. This might show the net of days I did study.

Areas to improve:
- "Indian Economy confidence dropped to 20 — schedule 3 revision sessions"
- "1 zero-study day — try to maintain consistency"

Next week recommendations:
- "Revise Indian Economy — confidence dropped to 20"
- "Aim to complete 10 new topics next week"

My reaction: This is the most useful single screen in the entire app. Concrete, specific, actionable. This is what I want from a study companion. If the whole app was just this weekly review + daily planner, it would be enough.

---

## Evaluation

### 1. Usability — 6/10

Good: Onboarding is smooth and warm. Planner is crystal clear — tap to complete, tap to defer. Syllabus tree is well-organized.

Bad: Dashboard is a wall of cards with no hierarchy. 9+ metrics compete for attention on the home screen. No onboarding for the dashboard itself — I'm thrown into "Velocity", "Buffer", "BRI", "Stress Thermometer" without any explanation of what they mean or why I should care.

Terminology problem: "Gravity" (why not just "importance-weighted progress"?), "Buffer Bank" (buffer of what? days? against what?), "BRI Score" (what's BRI?), "FSRS" (jargon from onboarding that's never explained). Even "Velocity" — I eventually understood it means "am I on pace", but the label doesn't communicate that.

### 2. Easiness — 7/10

What works: The daily planner genuinely reduces planning effort. I don't decide what to study — it decides for me. Revision scheduling is automatic. That's the killer feature.

Where friction appears:
- Understanding the dashboard requires effort
- Settings has "Persona Parameters" (Fatigue Threshold, Buffer Capacity, FSRS Target Retention, Burnout Threshold) — I have no idea what these do
- "Recalibration Engine" in settings with a "Recalibrate Now" button — recalibrate what?
- The mock test recording flow requires entering per-question data — tedious for a 100-question mock

### 3. Helpfulness — 7/10

Strong:
- Daily plan feels intelligent. Topics are prioritized by PYQ weight, accounts for fatigue, recovery, and revision needs.
- Automatic revision scheduling (FSRS-based) is genuinely helpful.
- Weekly review recommendations are specific and actionable.
- Mock test results directly influence the weakness radar and planner priorities.

Weak:
- Plan feels adaptive but not transparent. Changes priorities but doesn't explain why.
- System feels more reactive than proactive. Doesn't warn before problems.
- Generic recommendation text: "Focus on building fundamentals" after a 42% mock is obvious.

### 4. Progress Reassessment Quality — 5/10 (Weakest dimension)

What's missing:
- No single "here's what changed and why" screen
- Recalibration is invisible
- No before/after comparison
- No explanation on the planner when topics change

Does it feel like a black box or a transparent guide? 60% black box.

### 5. Trust Test — 6/10

I'd trust it more if each plan item had a one-line reason: "High PYQ weight + mock weakness" or "Revision due — last reviewed 5 days ago."

### 6. Clarity of Core Parameters — 5/10

| Parameter | Rating |
|-----------|--------|
| Velocity | 4/10 — "1.1x" means nothing without context |
| Buffer | 3/10 — "4.2 days banked" — banked against what? |
| Confidence | 8/10 — Fresh/Fading/Stale/Decayed is intuitive |
| Stress | 4/10 — Sub-signals (Vel/Buf/Tim/Con) are cryptic |
| Strategy Mode | 6/10 — Well-explained during onboarding, invisible after |

### 7. Brutally Honest Verdict

**Final rating: 6.5/10** — A powerful engine with a cockpit designed for pilots, not passengers. The average UPSC aspirant needs a GPS, not a flight instrument panel.

---
---

# Analysis & Rectification Prompts

## Weaknesses Identified (Priority Order)

| # | Weakness | Severity | Review Rating |
|---|----------|----------|---------------|
| W1 | Dashboard information overload — 9+ cards, no hierarchy, no guidance | High | Usability 6/10 |
| W2 | No explanations on plan items — system changes priorities silently | High | Reassessment 5/10 |
| W3 | No "What Changed" feed — cause-effect chain is broken across 4 tabs | High | Trust 6/10 |
| W4 | Missed-day silence — no acknowledgment, no encouragement | Medium | Emotional |
| W5 | Unclear terminology — Buffer, Velocity, BRI, Gravity are engineer-speak | Medium | Clarity 5/10 |
| W6 | Persona parameters exposed in Settings — implementation details shown to users | Medium | Easiness 7/10 |
| W7 | Recalibration is invisible — the smartest behavior is completely hidden | Medium | Reassessment 5/10 |
| W8 | Stress thermometer sub-signals cryptic (Vel/Buf/Tim/Con) | Low | Clarity 4/10 |
| W9 | Generic recommendation text after mock tests | Low | Helpfulness 7/10 |
| W10 | No proactive warnings (e.g., untouched subject before mock) | Low | Helpfulness 7/10 |

---

## Prompts (Give These to Claude One by One)

### Prompt 1 — Dashboard Hierarchy & Simplification

```
ExamPilot V2: The dashboard currently shows 9+ cards simultaneously (XP, Benchmark,
Current Affairs, Stress, Weakness Radar, Velocity, Buffer, Today's Plan, Confidence).
A user review says this is "information overload" and they'd "ignore 70% of the dashboard."

Redesign the dashboard screen in apps/mobile to have 3 tiers:
- PRIMARY (always visible): Today's Plan preview card, a single "How You're Doing"
  summary card that combines velocity + buffer + streak into one plain-English sentence
  (e.g., "You're on pace. 4 spare days banked. 5-day streak.")
- SECONDARY (collapsed section, tap to expand): Weakness Radar, Confidence Distribution,
  Stress Thermometer
- TERTIARY (moved to Progress tab or removed from dashboard): XP card, Benchmark Score,
  Current Affairs, Buffer Bank standalone card, Velocity standalone card

Update the Dashboard component hierarchy accordingly. Keep all existing API hooks — just
reorganize the UI layout and add the summary card.
```

### Prompt 2 — Plan Item Reasons

```
ExamPilot V2: Users can't understand WHY a topic appears in their daily plan. The planner
changes priorities silently after mock tests, confidence decay, or weakness detection,
but shows no explanation.

Add a `reason` field to each plan item. In apps/api/src/services/planner.ts, during
topic scoring and allocation, attach a one-line reason string to each planned topic:
- "Revision due — last reviewed X days ago"
- "High PYQ weight (X questions in past papers)"
- "Priority: scored X% in recent mock"
- "New topic — scheduled per daily target"
- "Confidence decayed to [stale/fading] — needs review"

Add the reason field to the plan item type in shared-types. On the mobile side, display
the reason as a subtle subtitle under each plan item in the Planner tab. Keep it short
and use muted text color.
```

### Prompt 3 — "What Changed" Activity Feed

```
ExamPilot V2: When the system adjusts priorities (after a mock, missed day, recalibration,
or confidence decay), users have to visit 4 different tabs to piece together what happened.
There's no narrative.

Add a "What Changed" activity feed system:

API side:
- Create a new service apps/api/src/services/activityFeed.ts that logs system events
  with user-facing messages
- Create migration for an `activity_feed` table: id, user_id, event_type, message,
  metadata (jsonb), created_at
- Hook into existing services via appEvents to log entries when:
  - Mock test recorded → "Mock score: 42%. Indian Economy (20%) flagged as weak."
  - Plan priorities shifted → "Added 2 Indian Economy topics based on mock results."
  - Recalibration triggered → "Adjusted your study pace — daily load reduced by 1 topic."
  - Missed day detected → "Missed Feb 26. Buffer used: 3.1 days remaining."
  - Confidence decay → "3 topics moved from Fresh to Fading — revisions scheduled."
- Add GET /api/activity-feed endpoint

Mobile side:
- Add a collapsible "Recent Changes" card on the dashboard (between primary and secondary
  tiers) showing last 3-5 feed entries with timestamps
- Each entry: icon + message + relative time ("2h ago", "Yesterday")
```

### Prompt 4 — Missed Day Acknowledgment

```
ExamPilot V2: When a user misses a study day and returns, the app shows no acknowledgment.
Numbers change silently. The reviewer says this feels like "indifference" and wants:
"Welcome back! You missed yesterday. Today's plan accounts for that."

Implement a missed-day welcome-back banner:

API side:
- In the planner service or a new utility, detect when the user's last activity was >24h ago
- Add a `missedDayInfo` field to the daily plan response: { daysMissed: number,
  bufferImpact: string, adjustmentNote: string }
- Example: { daysMissed: 1, bufferImpact: "-0.8 days", adjustmentNote: "Reduced today's
  load to 2 topics to ease back in" }

Mobile side:
- In the Planner screen, show a warm banner at the top when missedDayInfo is present:
  "Welcome back! You missed [X] day(s). We've adjusted today's plan — [adjustmentNote].
  Buffer: [bufferImpact]."
- Use a friendly tone, not punitive. Dismiss on tap.
- Also log this to the activity feed (Prompt 3).
```

### Prompt 5 — Plain English Metric Labels

```
ExamPilot V2: Core metrics use engineer terminology that users don't understand.

Update the mobile UI text for these metrics:

1. Velocity: Replace "1.1x" with "10% ahead of pace" or "On track — covering 10% more
   than needed per day." In the card, replace the label "Velocity" with "Study Pace."

2. Buffer: Replace "4.2d" with "4 spare days before your deadline." Replace label
   "Buffer Bank" with "Safety Margin." Add subtitle: "Days you can afford to miss and
   still finish on time."

3. BRI: Replace "BRI Score" with "Exam Readiness." Keep the percentage but add a
   one-liner: "Based on coverage, confidence, and mock performance."

4. Gravity: Replace "Gravity-weighted" with "Importance-weighted" everywhere in the UI.
   Add tooltip or subtitle: "Weighted by PYQ frequency and syllabus priority."

5. Stress Thermometer sub-signals: Replace "Vel" → "Pace", "Buf" → "Margin",
   "Tim" → "Time", "Con" → "Confidence"

Only change UI display text in apps/mobile. Do NOT rename API fields or database columns.
```

### Prompt 6 — Hide Persona Parameters from Settings

```
ExamPilot V2: The Settings screen exposes internal parameters (Fatigue Threshold: 85,
Buffer Capacity: 0.15, FSRS Target Retention: 0.9, Burnout Threshold). No aspirant
understands these. The reviewer calls them "implementation details, not user-facing controls."

In the mobile Settings screen:
- Remove the "Persona Parameters" section entirely from the visible UI
- Remove the "Recalibrate Now" button (or move it behind a hidden developer menu —
  triple-tap on version number)
- Keep the API endpoints functional — just stop exposing them in the default UI
- Replace with a simple toggle: "Auto-adjust study parameters based on my performance"
  (on by default) with a one-line explanation: "ExamPilot automatically fine-tunes your
  study plan based on your pace, mock scores, and revision patterns."

The strategy mode selector (Balanced/Aggressive/etc.) should remain visible — that's
a user-level choice.
```

### Prompt 7 — Visible Recalibration Summaries

```
ExamPilot V2: The recalibration engine auto-adjusts persona parameters but only sends
a vague notification: "Your plan needs a small adjustment." Users never see what changed
or why.

Make recalibration transparent:

API side:
- In apps/api/src/services/recalibration.ts, after each recalibration, generate a
  user-facing summary of what changed and why:
  - "Your daily topic load was reduced from 3 to 2 (velocity dropped below 0.8x for 3 days)"
  - "Revision frequency increased (3 topics dropped below 70% confidence this week)"
  - "Buffer capacity adjusted — you're 2 weeks ahead, so we've added more revision days"
- Store this summary in the activity feed (from Prompt 3)
- Include summary in the recalibration notification payload

Mobile side:
- When a recalibration notification is received, show an expandable card (not just a
  toast) with the summary
- Add recalibration entries to the "What Changed" feed on the dashboard
```

### Prompt 8 — Contextual Mock Test Recommendations

```
ExamPilot V2: After a 42% mock score, the recommendation is generic: "Focus on building
fundamentals." The reviewer wants specific guidance: "Your biggest gap is Indian Economy,
specifically fiscal policy topics. Spend 3 hours this week on chapters X and Y."

Improve mock test recommendations in the API:

In the mock test analysis service:
- For each weak subject (below 50% accuracy), identify the specific topics that were
  tested and answered incorrectly
- Cross-reference with the syllabus to find the parent topics/chapters
- Generate specific recommendations: "Indian Economy: 3/15 correct. Weakest areas:
  Fiscal Policy (0/4), Banking Reforms (1/3). Recommended: Review [specific topic names
  from syllabus] — estimated 4 hours."
- Rank recommendations by impact (PYQ weight × weakness severity)
- Limit to top 3 actionable recommendations

Update the mock analytics response type in shared-types to include these structured
recommendations. Update the mobile mock results screen to display them.
```

### Prompt 9 — Proactive Warnings

```
ExamPilot V2: The system is reactive (adjusts after bad performance) but not proactive
(doesn't warn before problems). Example: if Indian Economy hasn't been touched in 14 days
and a mock is approaching, there's no flag.

Add a proactive warning system:

API side — create apps/api/src/services/proactiveAlerts.ts:
- Run daily (via cron) to check for warning conditions:
  1. Subject neglect: Any subject untouched for >10 days → "You haven't studied [Subject]
     in [X] days. Consider scheduling a review."
  2. Pre-mock gaps: If a mock test is scheduled within 7 days, check for subjects with
     <30% coverage → "Mock in [X] days — [Subject] is at [Y]% coverage."
  3. Confidence cliff: >5 topics dropping to "stale" in next 3 days → "[X] topics will
     need revision soon. Plan lighter new-topic days."
  4. Buffer danger: Buffer below 2 days → "Your safety margin is thin. Consider a
     catch-up day."
- Log alerts to the activity feed
- Emit via appEvents for notification queueing

Mobile side:
- Show top alert as a banner on the dashboard (above the plan preview)
- Yellow for warnings, red for urgent
```

### Prompt 10 — Post-Mock Impact Summary Screen

```
ExamPilot V2: After recording a mock test, users have to visit 4 tabs to understand the
system's reaction. There's no single "here's what changed" view.

Add a post-mock impact summary screen:

After a mock test is submitted and analyzed, show a dedicated summary screen (modal or
new page) with:

1. "Score Overview" — overall %, subject breakdown (existing)
2. "Impact on Your Plan" (NEW):
   - Before/after comparison: "Indian Economy health: 60% → 25%"
   - Topics added to upcoming plan: list with reasons
   - Topics deprioritized: list with reasons
   - Estimated recovery time: "~1 week of focused study to restore Indian Economy"
3. "What We Changed" (NEW):
   - Weakness categories updated (which subjects moved to critical/weak)
   - Planner priority shifts
   - Any recalibration triggered
4. "Action Items" — top 3 specific recommendations (from Prompt 8)

API side: Create a GET /api/mock-tests/:id/impact endpoint that computes the before/after
diff. Mobile side: Navigate to this screen automatically after mock submission, with a
"Got it" button to dismiss.
```

---

## Recommended Execution Order

1. **Prompt 5** (Plain English labels) — quickest win, pure UI text changes
2. **Prompt 6** (Hide persona params) — quick win, removes confusion
3. **Prompt 2** (Plan item reasons) — highest impact on daily experience
4. **Prompt 1** (Dashboard redesign) — fixes the first impression
5. **Prompt 3** (Activity feed) — foundation for prompts 4, 7, 9
6. **Prompt 4** (Missed day banner) — depends on planner changes
7. **Prompt 7** (Recalibration summaries) — depends on activity feed
8. **Prompt 8** (Specific mock recommendations) — independent improvement
9. **Prompt 9** (Proactive warnings) — depends on activity feed
10. **Prompt 10** (Post-mock impact screen) — most complex, depends on 3 & 8
